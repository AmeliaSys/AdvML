{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NGlFZtiuU6Zu",
        "ct8eF_R9USuw",
        "CaiyEArYUVAc",
        "U4_WWffeUZeN",
        "4SIGJTy4UcdS",
        "uR-aHmLnZuTV",
        "ZdQaJM_xRGzi",
        "SBYPAmqxUtW9"
      ],
      "authorship_tag": "ABX9TyOj/xKFfNO8vX89y+S2uexu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeliaSys/AdvML/blob/IMDB-Movie-Review-Text-Classification/Movie_Review_Text_Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amelia Sayes\n",
        "\n",
        "ams2638\n",
        "\n",
        "Adv ML Assignment #3\n",
        "\n",
        "[Github Link](https://github.com/AmeliaSys/AdvML/blob/IMDB-Movie-Review-Text-Classification/Movie_Review_Text_Classification_Model.ipynb)\n",
        "\n"
      ],
      "metadata": {
        "id": "aelomNegUz35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##File Setup"
      ],
      "metadata": {
        "id": "NGlFZtiuU6Zu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLTIaMB3ChSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31960366-cd71-4ff0-895a-ddfdb0bc34c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aimodelshare==0.0.189\n",
            "  Downloading aimodelshare-0.0.189-py3-none-any.whl (967 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m967.8/967.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxconverter-common>=1.7.0\n",
            "  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore==1.29.82\n",
            "  Downloading botocore-1.29.82-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skl2onnx>=1.14.0\n",
            "  Downloading skl2onnx-1.14.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.0/294.0 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf2onnx\n",
            "  Downloading tf2onnx-1.14.0-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.2/451.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3==1.26.69\n",
            "  Downloading boto3-1.26.69-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydot==1.3.0\n",
            "  Downloading pydot-1.3.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting keras2onnx>=1.7.0\n",
            "  Downloading keras2onnx-1.7.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.3/96.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.6.3)\n",
            "Collecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==1.2.1\n",
            "  Downloading scikit_learn-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (2.0.0+cu118)\n",
            "Collecting docker==5.0.0\n",
            "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.19.6\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.7.0\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.9.2\n",
            "  Downloading tensorflow-2.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx==1.12.0\n",
            "  Downloading onnx-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (0.12.2)\n",
            "Collecting Pympler==0.9\n",
            "  Downloading Pympler-0.9.tar.gz (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.4/178.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pathlib>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.0.1)\n",
            "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (5.9.4)\n",
            "Collecting PyJWT>=2.4.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Collecting shortuuid>=1.0.8\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting onnxmltools>=1.6.1\n",
            "  Downloading onnxmltools-1.11.2-py2.py3-none-any.whl (322 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.7.0\n",
            "  Downloading scipy-1.7.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (2022.10.31)\n",
            "Collecting importlib-resources==5.10.0\n",
            "  Downloading importlib_resources-5.10.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from astunparse==1.6.3->aimodelshare==0.0.189) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse==1.6.3->aimodelshare==0.0.189) (0.40.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.82->aimodelshare==0.0.189) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.82->aimodelshare==0.0.189) (1.26.15)\n",
            "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /usr/local/lib/python3.9/dist-packages (from docker==5.0.0->aimodelshare==0.0.189) (2.27.1)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.9/dist-packages (from docker==5.0.0->aimodelshare==0.0.189) (1.5.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources==5.10.0->aimodelshare==0.0.189) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0->aimodelshare==0.0.189) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0->aimodelshare==0.0.189) (1.22.4)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.9/dist-packages (from pydot==1.3.0->aimodelshare==0.0.189) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.2.1->aimodelshare==0.0.189) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.2.1->aimodelshare==0.0.189) (1.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (16.0.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.4.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (23.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (0.32.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (0.4.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (2.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (3.8.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.53.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (67.6.1)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.7.0->aimodelshare==0.0.189) (1.11.1)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.9/dist-packages (from seaborn>=0.11.2->aimodelshare==0.0.189) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn>=0.11.2->aimodelshare==0.0.189) (3.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->aimodelshare==0.0.189) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->aimodelshare==0.0.189) (3.25.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->seaborn>=0.11.2->aimodelshare==0.0.189) (2022.7.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare==0.0.189) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare==0.0.189) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare==0.0.189) (3.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (2.2.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (1.8.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (2.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (3.4.3)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->aimodelshare==0.0.189) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime>=1.7.0->aimodelshare==0.0.189) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (6.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (3.2.2)\n",
            "Building wheels for collected packages: Pympler, wget, fire\n",
            "  Building wheel for Pympler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pympler: filename=Pympler-0.9-py3-none-any.whl size=164822 sha256=bfcfc29dc00a8f3066eb76ddb420a3e296799f355927c07b78cd3a9fbc0f5096\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/84/9a/0e7aa69b52bc9dc13ea25679c8d8f1dc11bc5b5289db23d9f3\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9676 sha256=a45c98917e067fccd26edc909e4c7d7b0dfecdc7f7775f3d758498173e0e80ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=92661d0b30640f4e322fb86de174da2de36dda97870bd57bb2f39ab3e800618b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n",
            "Successfully built Pympler wget fire\n",
            "Installing collected packages: wget, Pympler, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, shortuuid, scipy, PyJWT, pydot, protobuf, keras-preprocessing, jmespath, importlib-resources, humanfriendly, fire, scikit-learn, onnx, docker, coloredlogs, botocore, tf2onnx, s3transfer, onnxruntime, onnxconverter-common, google-auth-oauthlib, tensorboard, skl2onnx, keras2onnx, boto3, tensorflow, onnxmltools, aimodelshare\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 1.4.2\n",
            "    Uninstalling pydot-1.4.2:\n",
            "      Successfully uninstalled pydot-1.4.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.12.0\n",
            "    Uninstalling importlib-resources-5.12.0:\n",
            "      Successfully uninstalled importlib-resources-5.12.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.1\n",
            "    Uninstalling tensorboard-2.12.1:\n",
            "      Successfully uninstalled tensorboard-2.12.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyJWT-2.6.0 Pympler-0.9 aimodelshare-0.0.189 boto3-1.26.69 botocore-1.29.82 coloredlogs-15.0.1 docker-5.0.0 fire-0.5.0 flatbuffers-1.12 google-auth-oauthlib-0.4.6 humanfriendly-10.0 importlib-resources-5.10.0 jmespath-1.0.1 keras-2.9.0 keras-preprocessing-1.1.2 keras2onnx-1.7.0 onnx-1.12.0 onnxconverter-common-1.13.0 onnxmltools-1.11.2 onnxruntime-1.14.1 protobuf-3.19.6 pydot-1.3.0 s3transfer-0.6.0 scikit-learn-1.2.1 scipy-1.7.0 shortuuid-1.0.11 skl2onnx-1.14.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorflow-2.9.2 tensorflow-estimator-2.9.0 tf2onnx-1.14.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare==0.0.189"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3PiJXBhC5y-"
      },
      "outputs": [],
      "source": [
        "# Get competition data\n",
        "from aimodelshare import download_data\n",
        "download_data('public.ecr.aws/y2e2a1d6/sst2_competition_data-repository:latest') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT0qFCZFNzHq",
        "outputId": "e60f9cab-a8a1-480d-f924-172f60e0b547"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    The Rock is destined to be the 21st Century 's...\n",
              "1    The gorgeously elaborate continuation of `` Th...\n",
              "2    Singer/composer Bryan Adams contributes a slew...\n",
              "3                 Yet the act is still charming here .\n",
              "4    Whether or not you 're enlightened by any of D...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Set up X_train, X_test, and y_train_labels objects\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "X_train=pd.read_csv(\"sst2_competition_data/X_train.csv\", squeeze=True)\n",
        "X_test=pd.read_csv(\"sst2_competition_data/X_test.csv\", squeeze=True)\n",
        "\n",
        "y_train_labels=pd.read_csv(\"sst2_competition_data/y_train_labels.csv\", squeeze=True)\n",
        "\n",
        "# ohe encode Y data\n",
        "y_train = pd.get_dummies(y_train_labels)\n",
        "\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEzPoXPj3V7u"
      },
      "source": [
        "###2.   Preprocess data using keras tokenizer / Write and Save Preprocessor function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16QV9Y9TC3B3",
        "outputId": "ebe37a03-9af8-46ed-d8f2-db5e83406709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 40)\n",
            "(1821, 40)\n"
          ]
        }
      ],
      "source": [
        "# This preprocessor function makes use of the tf.keras tokenizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Build vocabulary from training text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# preprocessor tokenizes words and makes sure all documents have the same length\n",
        "def preprocessor(data, maxlen=40, max_words=10000):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X\n",
        "\n",
        "print(preprocessor(X_train).shape)\n",
        "print(preprocessor(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XPdswM4VSwd",
        "outputId": "5dfecf3d-39aa-4883-89b9-a28cd3eeec94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtgkM02MDpkO",
        "outputId": "78c38d8b-0af9-45af-819e-5230ac13c80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ],
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "    \n",
        "apiurl=\"https://rlxjxnoql9.execute-api.us-east-1.amazonaws.com/prod/m\" #This is the unique rest api that powers this specific Playground\n",
        "\n",
        "set_credentials(apiurl=apiurl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code to Submit Model"
      ],
      "metadata": {
        "id": "DircWS0wVA-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "Rxs1BEyvVWAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKNGSww8EGgi"
      },
      "outputs": [],
      "source": [
        "#Instantiate competition\n",
        "mycompetition= ai.Competition(apiurl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ql4wksyEUnP",
        "outputId": "ca9767ad-8291-4b73-a6f0-ba105f6c6a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 5s 54ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 98\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ],
      "source": [
        "#Submit Model: \n",
        "\n",
        "#-- Generate predicted y values (Model 1)\n",
        "#Note: Keras predict returns the predicted column index location for classification models\n",
        "prediction_column_index=model.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Discuss the dataset in general terms and describe why building a predictive model using this data might be practically useful.  Who could benefit from a model like this? Explain.\n"
      ],
      "metadata": {
        "id": "ct8eF_R9USuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of X data which are movie reviews and y data which is a label of the review either being positive or negative. The goal of this predictive model is to classify movie reviews correctly as either positive or negative. \n",
        "\n",
        "A predictive model able to classify sentiment of text is helpful in a number of ways. E.g. To calculate average sentiment across reviews for a movie. Platforms like IMDB and Rotten Tomatoes can use this information to produce a rating of movies. Not only is this helpful for the company, this is helpful to people who want to know how good a movie is."
      ],
      "metadata": {
        "id": "HTHjAdo-jzjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnmHxz30SiqZ",
        "outputId": "9f0a0e93-8124-42d6-ecfe-6d709da6deab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       The Rock is destined to be the 21st Century 's...\n",
              "1       The gorgeously elaborate continuation of `` Th...\n",
              "2       Singer/composer Bryan Adams contributes a slew...\n",
              "3                    Yet the act is still charming here .\n",
              "4       Whether or not you 're enlightened by any of D...\n",
              "                              ...                        \n",
              "6915                                      A real snooze .\n",
              "6916                                       No surprises .\n",
              "6917    We 've seen the hippie-turned-yuppie plot befo...\n",
              "6918    Her fans walked out muttering words like `` ho...\n",
              "6919                                  In this case zero .\n",
              "Name: text, Length: 6920, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SxTLvrr4SOIb",
        "outputId": "d0e3d5f6-102e-4b0d-e299-830a21f338c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Negative  Positive\n",
              "0            0         1\n",
              "1            0         1\n",
              "2            0         1\n",
              "3            0         1\n",
              "4            0         1\n",
              "...        ...       ...\n",
              "6915         1         0\n",
              "6916         1         0\n",
              "6917         0         1\n",
              "6918         1         0\n",
              "6919         1         0\n",
              "\n",
              "[6920 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0823124f-2041-45df-871c-c72e6a09e255\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Negative</th>\n",
              "      <th>Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6920 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0823124f-2041-45df-871c-c72e6a09e255')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0823124f-2041-45df-871c-c72e6a09e255 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0823124f-2041-45df-871c-c72e6a09e255');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Run at least three prediction models to try to predict the SST sentiment dataset well.\n"
      ],
      "metadata": {
        "id": "CaiyEArYUVAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 40"
      ],
      "metadata": {
        "id": "wKaexS7LW8OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.a. Use Embedding layers and LSTM layers in at least one model\n"
      ],
      "metadata": {
        "id": "U4_WWffeUZeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model #60"
      ],
      "metadata": {
        "id": "u5fbqimXWEY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(10000, 16, input_length=max_len))\n",
        "model2.add(LSTM(100, return_sequences=True, dropout=0.2))\n",
        "model2.add(LSTM(100, dropout=0.3))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEpo6_miYBMn",
        "outputId": "99beabe0-3c8b-42ab-e1bc-1e6bd7256ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 40, 16)            160000    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 40, 100)           46800     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 287,402\n",
            "Trainable params: 287,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model2.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyF0u5S7UV32",
        "outputId": "fc8c6401-e6c3-4a94-fcc5-2c2b4af4587a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "173/173 [==============================] - 21s 104ms/step - loss: 0.6593 - acc: 0.6275 - val_loss: 0.7635 - val_acc: 0.4191\n",
            "Epoch 2/5\n",
            "173/173 [==============================] - 17s 97ms/step - loss: 0.4811 - acc: 0.7731 - val_loss: 0.6508 - val_acc: 0.6922\n",
            "Epoch 3/5\n",
            "173/173 [==============================] - 15s 90ms/step - loss: 0.3638 - acc: 0.8447 - val_loss: 0.5762 - val_acc: 0.7095\n",
            "Epoch 4/5\n",
            "173/173 [==============================] - 15s 89ms/step - loss: 0.2996 - acc: 0.8737 - val_loss: 0.6502 - val_acc: 0.7038\n",
            "Epoch 5/5\n",
            "173/173 [==============================] - 16s 95ms/step - loss: 0.2523 - acc: 0.8990 - val_loss: 0.5360 - val_acc: 0.7601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVLW7W5pV-zw",
        "outputId": "cc71a020-b7fc-47ed-a9b6-5c6cf90cf8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   version  accuracy  f1_score  precision    recall  model_type\n",
            "6       60  0.792536  0.792094   0.795156  0.792587  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.b. Use Embedding layers and Conv1d layers in at least one model\n"
      ],
      "metadata": {
        "id": "4SIGJTy4UcdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 61"
      ],
      "metadata": {
        "id": "uR-aHmLnZuTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(10000, 8, input_length=max_len))\n",
        "model.add(layers.Conv1D(50, 7, activation='relu')) \n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCFcaMr5W4D_",
        "outputId": "415e0670-7939-4a9a-fef7-2aef082417cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 40, 8)             80000     \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 34, 50)            2850      \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 50)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,952\n",
            "Trainable params: 82,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63c8mxtaYQ0O",
        "outputId": "124b004f-b91c-441c-f4cc-0480383855f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 2s 6ms/step - loss: 0.6652 - acc: 0.6149 - val_loss: 0.8895 - val_acc: 0.1488\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.6280 - acc: 0.6239 - val_loss: 0.8109 - val_acc: 0.3266\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.5188 - acc: 0.7520 - val_loss: 0.7587 - val_acc: 0.5499\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4034 - acc: 0.8331 - val_loss: 0.5764 - val_acc: 0.7298\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.3286 - acc: 0.8680 - val_loss: 0.5973 - val_acc: 0.7153\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.2804 - acc: 0.8864 - val_loss: 0.5877 - val_acc: 0.7298\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.2423 - acc: 0.9005 - val_loss: 0.6672 - val_acc: 0.6879\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.2138 - acc: 0.9146 - val_loss: 0.5740 - val_acc: 0.7572\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.1915 - acc: 0.9230 - val_loss: 0.6872 - val_acc: 0.7153\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.1709 - acc: 0.9317 - val_loss: 0.6869 - val_acc: 0.7290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 61])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4No3LVyZwWU",
        "outputId": "55b03c2d-3412-4dbe-e62e-9659ffe1180c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   version  accuracy  f1_score  precision    recall  model_type\n",
            "6       60  0.792536  0.792094   0.795156  0.792587  Sequential\n",
            "7       61  0.788145  0.786414   0.798021  0.788245  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.c. Use transfer learning with glove embeddings for at least one of these models\n"
      ],
      "metadata": {
        "id": "n-z865j4UekS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model #84"
      ],
      "metadata": {
        "id": "ZdQaJM_xRGzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change max len to be 100 to be compatible with glove\n",
        "def preprocessor(data, maxlen=50, max_words=10000):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X\n",
        "\n",
        "print(preprocessor(X_train).shape)\n",
        "print(preprocessor(X_test).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRs4gI3iEC4N",
        "outputId": "5c34b0d2-3f8a-407b-bcbf-ea1a058d764b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 50)\n",
            "(1821, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1v5_LWGg56r",
        "outputId": "3d306a00-3259-4243-a8e2-240e7ed57ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-13 14:47:34--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-13 14:47:34--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-13 14:47:34--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-13 14:50:13 (5.17 MB/s) - ‘glove.6B.zip.1’ saved [862182753/862182753]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip glove.6B.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjBI75pNhQIm",
        "outputId": "680beb69-ff36-4365-965f-904a49abb38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract embedding data for 100 feature embedding matrix\n",
        "import os\n",
        "glove_dir = os.getcwd()\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.50d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVML8cfghS9H",
        "outputId": "f2c00b7a-75f7-443c-ff47-616fe3a3edb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400001 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 50 # change if you use txt files using larger number of features\n",
        "max_words = 10000\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "fMWXgIckhWe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "max_len = 50\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=max_len)) \n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GtVAitMi1v2",
        "outputId": "037fd5f7-20a2-4ee1-a5b0-75e491eb67d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 50, 50)            500000    \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 50)                125050    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 627,702\n",
            "Trainable params: 627,702\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "id": "0fTnPFoWIH8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNhrUSYHOlUG",
        "outputId": "e6dd85d7-7b4f-4574-8e7f-dd8a47a6ad3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 50, 50)            500000    \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 50)                125050    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 627,702\n",
            "Trainable params: 127,702\n",
            "Non-trainable params: 500,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate = 0.0001), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbq0G5MNjBLO",
        "outputId": "6ad0ab80-23eb-4107-c243-4181dcd9328c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "173/173 [==============================] - 3s 10ms/step - loss: 0.6689 - acc: 0.6109 - val_loss: 0.8645 - val_acc: 0.1510\n",
            "Epoch 2/20\n",
            "173/173 [==============================] - 2s 10ms/step - loss: 0.6356 - acc: 0.6201 - val_loss: 0.8439 - val_acc: 0.1929\n",
            "Epoch 3/20\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.6045 - acc: 0.6530 - val_loss: 0.8519 - val_acc: 0.2818\n",
            "Epoch 4/20\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.5755 - acc: 0.6895 - val_loss: 0.8204 - val_acc: 0.3996\n",
            "Epoch 5/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.5471 - acc: 0.7188 - val_loss: 0.8010 - val_acc: 0.4783\n",
            "Epoch 6/20\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.5206 - acc: 0.7444 - val_loss: 0.7489 - val_acc: 0.5621\n",
            "Epoch 7/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4968 - acc: 0.7619 - val_loss: 0.7064 - val_acc: 0.6199\n",
            "Epoch 8/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4750 - acc: 0.7782 - val_loss: 0.7397 - val_acc: 0.6033\n",
            "Epoch 9/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4541 - acc: 0.7944 - val_loss: 0.7595 - val_acc: 0.6069\n",
            "Epoch 10/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4334 - acc: 0.8047 - val_loss: 0.7394 - val_acc: 0.6301\n",
            "Epoch 11/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4143 - acc: 0.8168 - val_loss: 0.7287 - val_acc: 0.6380\n",
            "Epoch 12/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.3964 - acc: 0.8280 - val_loss: 0.7357 - val_acc: 0.6402\n",
            "Epoch 13/20\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.3787 - acc: 0.8354 - val_loss: 0.8752 - val_acc: 0.5780\n",
            "Epoch 14/20\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.3618 - acc: 0.8508 - val_loss: 0.8500 - val_acc: 0.5968\n",
            "Epoch 15/20\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.3443 - acc: 0.8620 - val_loss: 0.7603 - val_acc: 0.6402\n",
            "Epoch 16/20\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.3270 - acc: 0.8672 - val_loss: 0.7719 - val_acc: 0.6488\n",
            "Epoch 17/20\n",
            "173/173 [==============================] - 2s 10ms/step - loss: 0.3098 - acc: 0.8799 - val_loss: 0.8165 - val_acc: 0.6337\n",
            "Epoch 18/20\n",
            "173/173 [==============================] - 2s 9ms/step - loss: 0.2930 - acc: 0.8887 - val_loss: 0.8630 - val_acc: 0.6228\n",
            "Epoch 19/20\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.2760 - acc: 0.8970 - val_loss: 0.8942 - val_acc: 0.6221\n",
            "Epoch 20/20\n",
            "173/173 [==============================] - 2s 9ms/step - loss: 0.2590 - acc: 0.9059 - val_loss: 0.8960 - val_acc: 0.6185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 61, 84])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbgtl_ZGRKYD",
        "outputId": "21d61392-febf-4c60-9aa6-eb634a4d0267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "11       60  0.792536  0.792094   0.795156  0.792587  Sequential\n",
            "12       61  0.788145  0.786414   0.798021  0.788245  Sequential\n",
            "56       84  0.678375  0.675876   0.684226  0.678473  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Discuss which models performed better and point out relevant hyper-parameter values for successful models.\n",
        "Submit your best three models to the leader board for the SST Model Share competition."
      ],
      "metadata": {
        "id": "EFHiejrHUhK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 61, 84])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXJyKLs-Rdja",
        "outputId": "8d58ed75-3715-4ac8-93f0-9135da614724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "11       60  0.792536  0.792094   0.795156  0.792587  Sequential\n",
            "12       61  0.788145  0.786414   0.798021  0.788245  Sequential\n",
            "56       84  0.678375  0.675876   0.684226  0.678473  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest performing model, #60 is my first model which consists of 1 embedding layer with 10,000 input dimensions and 16 output dimensions, and 2 LSTM layers, each with 100 neurons. The first LSTM layer has a dropout rate of 0.2 and the secon has a dropout rate of 0.3. The model is flattened before the dense layer.This layer used the provided preprocessing technique that limits reviews to 40 words only. After training for 5 epochs in batches of 32, it rendered a f1_score of 0.792.\n",
        "\n",
        "This is only slightly higher than model #61, which uses 1 Embedding layer with 10000 input dimensions and 8 output dimensions and 1 Conv1D layer with 50 filters and a kernel size of 7. The Conv1D layer is activated by relu and is followed by Global MaxPooling 1D. This is a more simple model compared to #60. The f1_score on the test data is 0.786.\n",
        "\n",
        "The weakest model was #84 which uses transfer learning with glove embeddings. Even though this is a more compelx model, the results are significantly weaker than the other models with an f1-score of only 0.676."
      ],
      "metadata": {
        "id": "hYBENFF9R0fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Fit and submit up to three more models after learning from your team.\n"
      ],
      "metadata": {
        "id": "GVvK64GkUlys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.a. Model #85\n",
        "LSTM and Embedding model with more layers to improve on Model #60"
      ],
      "metadata": {
        "id": "Ig7zSzHeUqop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "max_len = 40\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 16, input_length=max_len))\n",
        "model.add(LSTM(50, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(50, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(80, dropout=0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5753329e-0999-4b8a-9b0e-1e157413139d",
        "id": "LsWxJEXFUx49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, 40, 16)            160000    \n",
            "                                                                 \n",
            " lstm_25 (LSTM)              (None, 40, 50)            13400     \n",
            "                                                                 \n",
            " lstm_26 (LSTM)              (None, 40, 50)            20200     \n",
            "                                                                 \n",
            " lstm_27 (LSTM)              (None, 80)                41920     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 80)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 2)                 162       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,682\n",
            "Trainable params: 235,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea80492e-c57c-4c29-f3c4-7cf0714fcf70",
        "id": "PSqiHjXIUx4-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 28s 117ms/step - loss: 0.6535 - acc: 0.6293 - val_loss: 0.7233 - val_acc: 0.4986\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 19s 112ms/step - loss: 0.4876 - acc: 0.7679 - val_loss: 0.5359 - val_acc: 0.7522\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 15s 84ms/step - loss: 0.3767 - acc: 0.8277 - val_loss: 0.7775 - val_acc: 0.6156\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 16s 91ms/step - loss: 0.3078 - acc: 0.8663 - val_loss: 0.5354 - val_acc: 0.7616\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 16s 93ms/step - loss: 0.2601 - acc: 0.8911 - val_loss: 0.4058 - val_acc: 0.8338\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 15s 87ms/step - loss: 0.2162 - acc: 0.9061 - val_loss: 0.6450 - val_acc: 0.7594\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 14s 84ms/step - loss: 0.1907 - acc: 0.9216 - val_loss: 0.5208 - val_acc: 0.8100\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 15s 87ms/step - loss: 0.1753 - acc: 0.9296 - val_loss: 0.7813 - val_acc: 0.7225\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 16s 94ms/step - loss: 0.1516 - acc: 0.9371 - val_loss: 0.7751 - val_acc: 0.7160\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 16s 93ms/step - loss: 0.1435 - acc: 0.9418 - val_loss: 0.6355 - val_acc: 0.7818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 85])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3cd40f-1cdb-4bc0-8a81-4972e278e1fb",
        "id": "NOhVXVkLTNqo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "3        85  0.814490  0.814199   0.816566  0.814534  Sequential\n",
            "12       60  0.792536  0.792094   0.795156  0.792587  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introducing more layers has improved f1 score from 0.79 to 0.81.\n",
        "\n",
        "There are now 3 LSTM layers in the model, the first two with 50 neurons and dropout rate of 0.2 and the final layer with 80 and a dropout rate of 0.3. Model #60 in comparison had 2 LSTM layers with 100 neurons each, the first with a dropout rate of 0.2 and the second with a dropout rate of 0.3. This model is also trained for 10 epochs instead of the original 5."
      ],
      "metadata": {
        "id": "StEBYXnNWZ5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.b. Model #86\n",
        "Retrain Model #85 with max_len = 100"
      ],
      "metadata": {
        "id": "SBYPAmqxUtW9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4812bcf3-7f9c-4a33-b82e-fb4fc67c1a6b",
        "id": "rMyc_wZpUQHY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 100)\n",
            "(1821, 100)\n"
          ]
        }
      ],
      "source": [
        "# This preprocessor function makes use of the tf.keras tokenizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Build vocabulary from training text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# preprocessor tokenizes words and makes sure all documents have the same length\n",
        "def preprocessor(data, maxlen=100, max_words=10000):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X\n",
        "\n",
        "print(preprocessor(X_train).shape)\n",
        "print(preprocessor(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "874dae35-3e76-411d-b8b8-8adb17a7c533",
        "id": "7PaR_nY5UQHY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "max_len = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 16, input_length=max_len))\n",
        "model.add(LSTM(50, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(50, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(80, dropout=0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx1qeKPaXAID",
        "outputId": "4f7c7168-b511-4b05-a3f1-e80003a2fe04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_20 (Embedding)    (None, 100, 16)           160000    \n",
            "                                                                 \n",
            " lstm_35 (LSTM)              (None, 100, 50)           13400     \n",
            "                                                                 \n",
            " lstm_36 (LSTM)              (None, 100, 50)           20200     \n",
            "                                                                 \n",
            " lstm_37 (LSTM)              (None, 80)                41920     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 80)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 2)                 162       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,682\n",
            "Trainable params: 235,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBJlCrvFXG2U",
        "outputId": "9d3a8d5f-183c-479d-93f0-c802dbe0c578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 56s 275ms/step - loss: 0.6495 - acc: 0.6339 - val_loss: 0.7335 - val_acc: 0.6062\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 50s 288ms/step - loss: 0.4858 - acc: 0.7711 - val_loss: 0.6673 - val_acc: 0.6431\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 48s 275ms/step - loss: 0.3638 - acc: 0.8387 - val_loss: 0.6045 - val_acc: 0.7247\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 49s 281ms/step - loss: 0.3377 - acc: 0.8696 - val_loss: 4.0732 - val_acc: 0.1488\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 49s 283ms/step - loss: 0.2696 - acc: 0.8941 - val_loss: 0.6206 - val_acc: 0.7312\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 47s 273ms/step - loss: 0.2242 - acc: 0.9099 - val_loss: 0.5288 - val_acc: 0.7601\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 50s 288ms/step - loss: 0.1888 - acc: 0.9230 - val_loss: 0.5673 - val_acc: 0.7782\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 47s 274ms/step - loss: 0.1700 - acc: 0.9306 - val_loss: 0.5501 - val_acc: 0.7724\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 50s 288ms/step - loss: 0.1567 - acc: 0.9375 - val_loss: 0.6205 - val_acc: 0.7630\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 49s 282ms/step - loss: 0.1391 - acc: 0.9418 - val_loss: 0.6530 - val_acc: 0.7659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 85, 86])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEYJ-o_OZI_r",
        "outputId": "88d5fe81-af66-462c-dd49-19ce55264524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "3        85  0.814490  0.814199   0.816566  0.814534  Sequential\n",
            "7        86  0.803513  0.802136   0.812417  0.803605  Sequential\n",
            "14       60  0.792536  0.792094   0.795156  0.792587  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greater max_len performances is actually weaker than max_len 40 as default preprocessing and the same exact model architecture. 0.802 f1_score vs. 0.814. Still performs better than model #60."
      ],
      "metadata": {
        "id": "jzmmgPsVbpC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.c. Model #97\n",
        "Bidirectional LSTM"
      ],
      "metadata": {
        "id": "5nwkds4GUvSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "maxlen = 40\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 16, input_length=maxlen))\n",
        "model.add(Bidirectional(LSTM(50, return_sequences = True, dropout = 0.2)))\n",
        "model.add(LSTM(50, dropout = 0.3))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "ax3xjfhGTYFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=100,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAWXqv6mWJJD",
        "outputId": "5b117f52-fdd2-4d3e-8c50-3598cf67ee93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "56/56 [==============================] - 24s 257ms/step - loss: 0.6604 - acc: 0.6142 - val_loss: 1.8926 - val_acc: 0.1936\n",
            "Epoch 2/5\n",
            "56/56 [==============================] - 8s 151ms/step - loss: 0.5005 - acc: 0.7697 - val_loss: 0.4933 - val_acc: 0.8071\n",
            "Epoch 3/5\n",
            "56/56 [==============================] - 12s 220ms/step - loss: 0.3556 - acc: 0.8475 - val_loss: 0.6410 - val_acc: 0.6799\n",
            "Epoch 4/5\n",
            "56/56 [==============================] - 9s 169ms/step - loss: 0.2738 - acc: 0.8940 - val_loss: 0.5301 - val_acc: 0.7803\n",
            "Epoch 5/5\n",
            "56/56 [==============================] - 12s 209ms/step - loss: 0.2121 - acc: 0.9198 - val_loss: 0.4735 - val_acc: 0.7760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 85, 86, 97])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkJR6Z5IYeqN",
        "outputId": "c0f206b7-a6d3-4e10-c01c-28b1ca7a2358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "3        85  0.814490  0.814199   0.816566  0.814534  Sequential\n",
            "4        97  0.811196  0.810978   0.812730  0.811235  Sequential\n",
            "8        86  0.803513  0.802136   0.812417  0.803605  Sequential\n",
            "16       60  0.792536  0.792094   0.795156  0.792587  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bidirectional layer model is the second top performing model with a f1 score of 0.811, only just behind #85 at 0.814. \n",
        "\n",
        "This model has 1 embedding layer with 10000 inputs and 16 outputs, 1 bidirectional LSTM layer with 50 neurons, and dropout of 0.2, and a regular LSTM layer with 50 neurons and dropout of 0.3. The dropout layers were introduced to prevent overfitting. "
      ],
      "metadata": {
        "id": "aATnUDldkzNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Discuss results\n",
        "Discuss which models you tried and which models performed better and point out relevant hyper-parameter values for successful models."
      ],
      "metadata": {
        "id": "W_X24hwBUoof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 85, 86, 97, 61, 84])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnPayxZdnYJp",
        "outputId": "5fa6ca37-013b-43f1-f818-c1e8092cbd31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "3        85  0.814490  0.814199   0.816566  0.814534  Sequential\n",
            "4        97  0.811196  0.810978   0.812730  0.811235  Sequential\n",
            "8        86  0.803513  0.802136   0.812417  0.803605  Sequential\n",
            "16       60  0.792536  0.792094   0.795156  0.792587  Sequential\n",
            "18       61  0.788145  0.786414   0.798021  0.788245  Sequential\n",
            "69       84  0.678375  0.675876   0.684226  0.678473  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weaker Performing Models:** Of the 6 models I created, the three that performed the worst used glove embedding + transfer learning (#84), and embedding layers + conv1D layers (#61). Of my initial models, #60 was the best performer with an f1 score of 0.79. This model consists of 1 embedding layer with 10,000 input dimensions and 16 output dimensions, and 2 LSTM layers, each with 100 neurons. The first LSTM layer has a dropout rate of 0.2 and the secon has a dropout rate of 0.3. The model is flattened before the dense layer.This layer used the provided preprocessing technique that limits reviews to 40 words only. After training for 5 epochs in batches of 32, it rendered a f1_score of 0.792.\n",
        "\n",
        "I then improved upon model #60 in part 4 and produced 3 new models:\n",
        "\n",
        "**Best Performing Model: Model #85:** Model #85 is very similar to model #60 but more complex. This mdoel has 3 LSTM layers instead of 2 as in #60. The first two have 50 neurons and a dropout of 0.2 and the third layer has 80 neurons with dropout of 0.3. This model is also trained for 10 epochs instead of the original 5. This improved performance from 0.792 to 0.814.\n",
        "\n",
        "Model #97 and #86 were also from part 4 of the assignment, and aimed to improve upon the performance of model #60. \n",
        "\n",
        "**Second Best Performing Model: Model #97:** This model rendered a f1-score of 0.813 which is very similar to the performance of #85 at 0.814. In this model I experimented with bidirectional LSTM layers. This model has 1 embedding layer with 10000 inputs and 16 outputs, 1 bidirectional LSTM layer with 50 neurons, and dropout of 0.2, and a regular LSTM layer with 50 neurons and dropout of 0.3. The dropout layers were introduced to prevent overfitting.  \n",
        "\n",
        "In model #86 I experimented with different max lengths of the input text. Here, I changed the preprocessing of the text to a max length of 100 instead of 40. I used the same arhictecture as model #85 and found that this actually decreased performance. \n",
        "\n"
      ],
      "metadata": {
        "id": "OBjwZ54onmMR"
      }
    }
  ]
}